# ELARA-Evolving-Language-Adaptive-Response-Agent
ELARA (Evolving Language & Adaptive Response Agent) is an AI-powered chatbot built from scratch using traditional NLP and machine learning techniques. Designed to understand user queries, adapt dynamically, and improve over time, ELARA combines structured learning, intent recognition, and active learning to enhance conversational flow.

# Chatbot from Scratch

## Overview

This project implements a chatbot **without using any pre-trained models or external APIs**. Instead, it leverages traditional **Natural Language Processing (NLP) techniques** and a **Support Vector Machine (SVM) classifier** trained from scratch. The chatbot continuously learns by logging misclassified queries and integrating user feedback through **active learning.**

## Features

- **Intent Recognition** using **SVM + TF-IDF** trained on a **merged dataset** (MultiWOZ 2.2 + Clinc OOS + Rasa NLU).
- **Rule-based Fallback Mechanism** for handling unknown inputs.
- **Memory System** to retain the last **30 messages** and extract key user information for context-aware responses.
- **Active Learning System** to improve accuracy over time by reviewing misclassified inputs.
- **Structured Storage** of conversation logs in CSV for retraining.
- **Command-Line Interface (CLI)** with planned **GUI integration**.

## Project Structure

```
ðŸ“‚ chatbot_project
 â”œâ”€â”€ ðŸ“‚ dataset_raw             # Original datasets (downloaded)
 â”‚   â”œâ”€â”€ multiwoz_v22/         # MultiWOZ 2.2 raw dataset
 â”‚   â”œâ”€â”€ clinc_oos/            # Clinc OOS dataset
 â”‚   â”œâ”€â”€ rasa_nlu/             # Rasa NLU dataset
 â”‚
 â”œâ”€â”€ ðŸ“‚ data                   # Merged + Preprocessed dataset
 â”‚   â”œâ”€â”€ merged_data.json      # Final combined dataset
 â”‚   â”œâ”€â”€ merged_data.csv       # Same dataset in CSV format
 â”‚   â”œâ”€â”€ train.json            # Training set
 â”‚   â”œâ”€â”€ validation.json       # Validation set
 â”‚   â”œâ”€â”€ test.json             # Test set
 â”‚
 â”œâ”€â”€ ðŸ“‚ models                 # Saved models
 â”‚   â”œâ”€â”€ chatbot_model.pkl     # Trained SVM model
 â”‚   â”œâ”€â”€ vectorizer.pkl        # TF-IDF vectorizer for text processing
 â”‚
 â”œâ”€â”€ ðŸ“‚ src
 â”‚   â”œâ”€â”€ preprocess.py         # Merges datasets & splits into train/test/val
 â”‚   â”œâ”€â”€ train.py              # Trains the chatbot using SVM
 â”‚   â”œâ”€â”€ chatbot.py            # Main chatbot interface
 â”‚   â”œâ”€â”€ memory.py             # Stores and retrieves important user details
 â”‚   â”œâ”€â”€ active_learning.py    # Processes misclassified inputs
 â”‚
 â”œâ”€â”€ README.md
 â”œâ”€â”€ requirements.txt
 â”œâ”€â”€ run_chatbot.py            # Entry point to launch chatbot
```

## Setup Instructions

### **1. Install Dependencies**

```bash
pip install -r requirements.txt
```

### **2. Prepare Datasets**

```bash
python src/preprocess.py
```

This script:
- **Merges** datasets from `dataset_raw/` (MultiWOZ 2.2, Clinc OOS, Rasa NLU).
- **Cleans** text and formats it properly.
- **Splits** data into `train.json`, `validation.json`, and `test.json`.

### **3. Train the Chatbot**

```bash
python src/train.py
```

This script:
- Loads and preprocesses the dataset from `data/merged_data.json`.
- Trains an **SVM classifier** with **TF-IDF features**.
- Saves the trained model (`chatbot_model.pkl`) and **TF-IDF vectorizer**.

### **4. Run the Chatbot**

```bash
python run_chatbot.py
```

- Stores the last **30 messages** for short-term memory.
- Extracts long-term user details for personalized responses.
- Logs misclassified inputs for future improvements.

## Improving the Chatbot

### **Misclassification Logging**

Whenever the chatbot fails to classify an input correctly, it is logged in `misclassified.csv` with:

- User input
- Predicted intent
- Correct intent (if user provides feedback)

### **Retraining with Active Learning**

Run the following script **periodically** to integrate new data and improve accuracy:

```bash
python src/active_learning.py
```

This script:
- Reads `misclassified.csv`.
- Allows manual correction of misclassified intents.
- Updates `merged_data.json` with new examples.
- Retrains the model with the improved dataset.

## Future Enhancements

âœ… GUI with **Tkinter/PyQt** âœ… Context-aware responses using **more advanced memory management** âœ… Improved response diversity using **template-based generation**

## Credits

This chatbot was developed using **NLTK, Scikit-learn, and JSON-based intent storage**, following a structured and scalable approach for continuous learning. ðŸš€


# ðŸš€ Chatbot Implementation Workflow

## **Phase 1: Data Preparation & Preprocessing**

### **1.1 Select & Merge Datasets**
âœ… Use **Clinc OOS** (primary dataset) + **Rasa NLU** (secondary dataset)  
âœ… **Remove duplicate intents & balance classes**  
âœ… **Standardize format** (Ensure both datasets follow the same JSON structure)  
âœ… Store merged dataset as `intents.json`

### **1.2 Preprocessing Pipeline**
âœ… **Tokenization** (split input into words)  
âœ… **Lowercasing** (convert all text to lowercase)  
âœ… **Stemming** (reduce words to root form)  
âœ… **TF-IDF Vectorization** (convert words into numerical features for SVM)  
âœ… Use **NLTK** for tokenization & stemming  

---

## **Phase 2: Intent Classification System**

### **2.1 Train SVM for Intent Classification**
âœ… Train **SVM classifier** on labeled intent data  
âœ… Use **TF-IDF vectorized text features**  
âœ… Train-Test Split: **80% training, 20% testing**  
âœ… Evaluate accuracy & fine-tune parameters if necessary  
âœ… Save trained model as `intent_classifier.pkl`

### **2.2 Implement Misclassification Logging & Active Learning**
âœ… If **confidence score < threshold**, log query as `unknown_intents.csv`  
âœ… Periodically **review misclassified queries**  
âœ… Add relevant ones to dataset & retrain SVM model  

---

## **Phase 3: Response Generation System**

### **3.1 Rule-Based Response System (Initial Implementation)**
âœ… Create `responses.json` with predefined answers  
âœ… Implement **randomized responses** for each intent  
âœ… Fallback: If intent is unknown, respond with **"Could you clarify?"**

### **3.2 Advanced Response Handling (Phase 2 Upgrade)**
âœ… Add **dynamic template-based responses** (e.g., `"The weather in {city} is {weather}."`)  
âœ… Implement **feedback collection system** (ask "Was this helpful? Y/N")  
âœ… Store feedback in `feedback_log.csv`  

---

## **Phase 4: Context & Memory Handling**

### **4.1 Short-Term Memory (Chat History)**
âœ… Store last **30 messages** in a rolling buffer  
âœ… Use stored context to improve replies  

### **4.2 Long-Term Memory (User Context Storage)**
âœ… Detect **key user information** (e.g., "I'm 18 years old.")  
âœ… Store key details in `user_profiles.json`  
âœ… Retrieve context for future replies  

---

## **Phase 5: User Interface & Deployment**

### **5.1 Build CLI Interface (Initial Deployment)**
âœ… Simple text-based chatbot interface in Python  
âœ… Load `intent_classifier.pkl` and `responses.json`  
âœ… Process user queries & generate responses  

### **5.2 GUI Upgrade (Phase 2 Enhancement)**
âœ… Build **Tkinter-based GUI** for a better user experience  
âœ… Display **chat history + response feedback buttons**  

---

## **Phase 6: Training & Continuous Improvement**

### **6.1 Model Retraining Process**
âœ… Every **X interactions**, review `unknown_intents.csv`  
âœ… Add high-quality misclassified queries to dataset  
âœ… Retrain `intent_classifier.pkl` with updated data  

### **6.2 Performance Optimization**
âœ… Experiment with **hyperparameters** (C value in SVM)  
âœ… Optimize **TF-IDF vectorization** (max features, n-grams)  
âœ… Speed up inference with caching for frequent queries  

---



